{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <h1 style=\"text-align:center\">ASI   </h1>\n",
    "<h2 style=\"text-align:center\">Naïve Bayes Classifier and Bayesian Linear Regression</h2>\n",
    "<h3 style=\"text-align:center\">Matteo Fiore</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import MNIST\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "import functools\n",
    "import pickle\n",
    "import time\n",
    "classes = [0,1,2,3,4,5,6,7,8,9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#327191; vertical-align: middle; padding:5px 0px 10px 10px;\">\n",
    "    <h1><font color='white'>Load Datasets</font></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f33a82e6a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label of image is --> 6\n"
     ]
    }
   ],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "base_cfar10 = 'cifar-10-batches-py/'\n",
    "cfar10_files = ['data_batch_1','data_batch_2','data_batch_3','data_batch_4','data_batch_5']\n",
    "\n",
    "data_cfar10 = []\n",
    "for f in cfar10_files:\n",
    "    data_cfar10.append(unpickle(base_cfar10+f))\n",
    "cfar10_test = unpickle(base_cfar10+'test_batch')\n",
    "\n",
    "cfar10_meta = unpickle(base_cfar10+'batches.meta')\n",
    "\n",
    "cfar10_training_images = np.array([d[b'data'] for d in data_cfar10]).flatten().reshape(50000,3072)\n",
    "cfar10_training_labels = np.array([d[b'labels'] for d in data_cfar10]).flatten()\n",
    "cfar10_test_images = cfar10_test[b'data']\n",
    "cfar10_test_labels = np.array(cfar10_test[b'labels'])\n",
    "\n",
    "# example \n",
    "im = np.reshape(cfar10_training_images[0], (32,32,3), order='F')\n",
    "plt.imshow(im)\n",
    "plt.show()\n",
    "print('label of image is --> '+str(cfar10_training_labels[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADXZJREFUeJzt3X+IHPUZx/HPU5uAaFGT0uMwtjH+KETRVE4pEoqlGq3E\nxIBogn+ktPT6hy0txl+kgkIRS6mW/hVIMZhoa9NwMUYtDTXUmIIJOSWJRmM1ctGES64hogkiNcnT\nP3auPfXmu5uZ2Z29PO8XHLc7z+7Mw3Kfm5md3e/X3F0A4vlS3Q0AqAfhB4Ii/EBQhB8IivADQRF+\nICjCDwRF+IGgCD8Q1Jc7uTEz4+OEQJu5u7XyuFJ7fjO7wczeMrN3zOy+MusC0FlW9LP9ZnaapH9J\nuk7SPknbJC1y9zcSz2HPD7RZJ/b8V0l6x93fdff/SPqzpPkl1gegg8qE/1xJ74+5vy9b9hlm1m9m\ng2Y2WGJbACrW9jf83H25pOUSh/1ANymz598v6bwx96dlywBMAGXCv03SRWZ2vplNlrRQ0vpq2gLQ\nboUP+939mJn9VNIGSadJWuHuuyrrDEBbFb7UV2hjnPMDbdeRD/kAmLgIPxAU4QeCIvxAUIQfCIrw\nA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IqqNDd6OYu+66K1k//fTTc2uXXXZZ8rm33HJLoZ5G\nLVu2LFl/+eWXc2tPPPFEqW2jHPb8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAUo/d2gdWrVyfrZa/F\n12nPnj25tWuvvTb53Pfee6/qdkJg9F4ASYQfCIrwA0ERfiAowg8ERfiBoAg/EFSp7/Ob2ZCkI5KO\nSzrm7n1VNHWqqfM6/u7du5P1DRs2JOszZsxI1m+66aZk/YILLsit3X777cnnPvzww8k6yqliMI/v\nuvuhCtYDoIM47AeCKht+l/SCmb1iZv1VNASgM8oe9s929/1m9jVJfzez3e7+0tgHZP8U+McAdJlS\ne35335/9HpH0tKSrxnnMcnfv481AoLsUDr+ZnWFmXxm9LWmOpNeragxAe5U57O+R9LSZja7nT+7+\nt0q6AtB2hcPv7u9KurzCXiasvr70Gc2CBQtKrX/Xrl3J+rx583Jrhw6lr8IePXo0WZ88eXKyvmXL\nlmT98svz/0SmTp2afC7ai0t9QFCEHwiK8ANBEX4gKMIPBEX4gaCYorsCvb29yXr2WYhczS7lXX/9\n9cn68PBwsl7GkiVLkvWZM2cWXvfzzz9f+Lkojz0/EBThB4Ii/EBQhB8IivADQRF+ICjCDwTFdf4K\nPPvss8n6hRdemKwfOXIkWT98+PBJ91SVhQsXJuuTJk3qUCeoGnt+ICjCDwRF+IGgCD8QFOEHgiL8\nQFCEHwiK6/wdsHfv3rpbyHX33Xcn6xdffHGp9W/durVQDe3Hnh8IivADQRF+ICjCDwRF+IGgCD8Q\nFOEHgjJ3Tz/AbIWkuZJG3P3SbNkUSaslTZc0JOlWd/+g6cbM0htD5ebOnZusr1mzJllvNkX3yMhI\nsp4aD2DTpk3J56IYd09PFJFpZc//uKQbPrfsPkkb3f0iSRuz+wAmkKbhd/eXJH1+KJn5klZmt1dK\nurnivgC0WdFz/h53H50j6oCknor6AdAhpT/b7+6eOpc3s35J/WW3A6BaRff8B82sV5Ky37nv+rj7\ncnfvc/e+gtsC0AZFw79e0uLs9mJJz1TTDoBOaRp+M3tK0suSvmlm+8zsR5J+Lek6M3tb0rXZfQAT\nSNNzfndflFP6XsW9oA36+tJnW82u4zezevXqZJ1r+d2LT/gBQRF+ICjCDwRF+IGgCD8QFOEHgmLo\n7lPAunXrcmtz5swpte5Vq1Yl6/fff3+p9aM+7PmBoAg/EBThB4Ii/EBQhB8IivADQRF+IKimQ3dX\nujGG7i6kt7c3Wd+xY0duberUqcnnHjp0KFm/+uqrk/U9e/Yk6+i8KofuBnAKIvxAUIQfCIrwA0ER\nfiAowg8ERfiBoPg+/wQwMDCQrDe7lp/y5JNPJutcxz91secHgiL8QFCEHwiK8ANBEX4gKMIPBEX4\ngaCaXuc3sxWS5koacfdLs2UPSvqxpH9nD1vq7n9tV5Onunnz5iXrV1xxReF1v/jii8n6Aw88UHjd\nmNha2fM/LumGcZb/zt1nZT8EH5hgmobf3V+SdLgDvQDooDLn/D8zs51mtsLMzqmsIwAdUTT8yyTN\nkDRL0rCkR/IeaGb9ZjZoZoMFtwWgDQqF390Puvtxdz8h6Q+Srko8drm797l7X9EmAVSvUPjNbOxw\nsgskvV5NOwA6pZVLfU9JukbSV81sn6QHJF1jZrMkuaQhST9pY48A2qBp+N190TiLH2tDL6esZt+3\nX7p0abI+adKkwtvevn17sn706NHC68bExif8gKAIPxAU4QeCIvxAUIQfCIrwA0ExdHcHLFmyJFm/\n8sorS61/3bp1uTW+sos87PmBoAg/EBThB4Ii/EBQhB8IivADQRF+IChz985tzKxzG+sin3zySbJe\n5iu7kjRt2rTc2vDwcKl1Y+Jxd2vlcez5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAovs9/CpgyZUpu\n7dNPP+1gJ1/04Ycf5taa9dbs8w9nnXVWoZ4k6eyzz07W77zzzsLrbsXx48dza/fee2/yuR9//HEl\nPbDnB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgml7nN7PzJK2S1CPJJS1399+b2RRJqyVNlzQk6VZ3\n/6B9rSLPzp07624h15o1a3JrzcYa6OnpSdZvu+22Qj11uwMHDiTrDz30UCXbaWXPf0zSEnefKenb\nku4ws5mS7pO00d0vkrQxuw9ggmgafncfdvdXs9tHJL0p6VxJ8yWtzB62UtLN7WoSQPVO6pzfzKZL\n+pakrZJ63H30uO2AGqcFACaIlj/bb2ZnShqQ9At3/8js/8OEubvnjc9nZv2S+ss2CqBaLe35zWyS\nGsH/o7uvzRYfNLPerN4raWS857r7cnfvc/e+KhoGUI2m4bfGLv4xSW+6+6NjSuslLc5uL5b0TPXt\nAWiXpkN3m9lsSZslvSbpRLZ4qRrn/X+R9HVJe9W41He4ybpCDt29du3aZH3+/Pkd6iSWY8eO5dZO\nnDiRW2vF+vXrk/XBwcHC6968eXOyvmXLlmS91aG7m57zu/s/JeWt7HutbARA9+ETfkBQhB8IivAD\nQRF+ICjCDwRF+IGgmKK7C9xzzz3JetkpvFMuueSSZL2dX5tdsWJFsj40NFRq/QMDA7m13bt3l1p3\nN2OKbgBJhB8IivADQRF+ICjCDwRF+IGgCD8QFNf5gVMM1/kBJBF+ICjCDwRF+IGgCD8QFOEHgiL8\nQFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUE3Db2bnmdk/zOwNM9tlZj/Plj9oZvvNbHv2\nc2P72wVQlaaDeZhZr6Red3/VzL4i6RVJN0u6VdJRd/9tyxtjMA+g7VodzOPLLaxoWNJwdvuImb0p\n6dxy7QGo20md85vZdEnfkrQ1W/QzM9tpZivM7Jyc5/Sb2aCZDZbqFEClWh7Dz8zOlLRJ0kPuvtbM\neiQdkuSSfqXGqcEPm6yDw36gzVo97G8p/GY2SdJzkja4+6Pj1KdLes7dL22yHsIPtFllA3iamUl6\nTNKbY4OfvRE4aoGk10+2SQD1aeXd/tmSNkt6TdKJbPFSSYskzVLjsH9I0k+yNwdT62LPD7RZpYf9\nVSH8QPsxbj+AJMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQ\nTQfwrNghSXvH3P9qtqwbdWtv3dqXRG9FVdnbN1p9YEe/z/+FjZsNuntfbQ0kdGtv3dqXRG9F1dUb\nh/1AUIQfCKru8C+vefsp3dpbt/Yl0VtRtfRW6zk/gPrUvecHUJNawm9mN5jZW2b2jpndV0cPecxs\nyMxey2YernWKsWwatBEze33Msilm9nczezv7Pe40aTX11hUzNydmlq71teu2Ga87fthvZqdJ+pek\n6yTtk7RN0iJ3f6OjjeQwsyFJfe5e+zVhM/uOpKOSVo3OhmRmv5F02N1/nf3jPMfd7+2S3h7USc7c\n3Kbe8maW/oFqfO2qnPG6CnXs+a+S9I67v+vu/5H0Z0nza+ij67n7S5IOf27xfEkrs9sr1fjj6bic\n3rqCuw+7+6vZ7SOSRmeWrvW1S/RVizrCf66k98fc36fumvLbJb1gZq+YWX/dzYyjZ8zMSAck9dTZ\nzDiaztzcSZ+bWbprXrsiM15XjTf8vmi2u8+S9H1Jd2SHt13JG+ds3XS5ZpmkGWpM4zYs6ZE6m8lm\nlh6Q9At3/2hsrc7Xbpy+annd6gj/fknnjbk/LVvWFdx9f/Z7RNLTapymdJODo5OkZr9Hau7nf9z9\noLsfd/cTkv6gGl+7bGbpAUl/dPe12eLaX7vx+qrrdasj/NskXWRm55vZZEkLJa2voY8vMLMzsjdi\nZGZnSJqj7pt9eL2kxdntxZKeqbGXz+iWmZvzZpZWza9d18147e4d/5F0oxrv+O+R9Ms6esjpa4ak\nHdnPrrp7k/SUGoeBn6rx3siPJE2VtFHS25JekDSli3p7Qo3ZnHeqEbTemnqbrcYh/U5J27OfG+t+\n7RJ91fK68Qk/ICje8AOCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/ENR/AbqbWwLyUU7XAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f33a9f67208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label of image is --> 2\n"
     ]
    }
   ],
   "source": [
    "mndata = MNIST('.',return_type='numpy')\n",
    "mnist_training_images, mnist_training_labels = mndata.load_training()\n",
    "mnist_testing_images, mnist_testing_labels = mndata.load_testing()\n",
    "\n",
    "# example of data\n",
    "im = np.reshape(mnist_testing_images[1], (28,28))\n",
    "plt.imshow(im, cmap='gray')\n",
    "plt.show()\n",
    "print('label of image is --> '+str(mnist_testing_labels[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#327191; vertical-align: middle; padding:5px 0px 10px 10px;\">\n",
    "    <h1><font color='white'>Comment on dimensionality and distribution of classes</font></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#d9e6fc; padding:15px 15px 15px 15px;\"> \n",
    "The classes' distribution can affect the classification, since if the prior for class A is a lot greater than prior of the other classes, the product <i>likelihood*prior</i> will be also greater (supposing the likelihood is not varying too much from one class to another) and will \"attract\" more data.<br><br>\n",
    "Focusing on the dimensionality, the highest the dimensionality, the highest the number of combination of the features. If there are too many features but not enough data, it is not possible to have a sufficient number of data for each possible combination of features. This results in overfitting: we are creating a model using a set of data that describes only a part of the total dataset, that correspond to not being able to caracterize all the dataset corresponding to all the possible features.  \n",
    "  \n",
    "Below there is a plot showing the distribution of the elements per class: in the MNIST dataset it is possible to notice a greater variance in the distribution.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4UAAAG5CAYAAAA595FfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFAIAAGxMKAQAANjYF83nopSGvMgZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f88d7145a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.subplot(121)\n",
    "\n",
    "\n",
    "plt.bar(range(0,10),[len(cfar10_training_labels[cfar10_training_labels==c]) for c in range(0,10)])\n",
    "plt.title('CFAR10 Dataset')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of elements')\n",
    "\n",
    "plt.subplot(122)\n",
    "\n",
    "plt.bar(range(0,10),[len(mnist_training_labels[mnist_training_labels==c]) for c in range(0,10)])\n",
    "plt.title('MNIST Dataset')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of elements')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#327191; vertical-align: middle; padding:5px 0px 10px 10px;\">\n",
    "    <h1><font color='white'>Data Cleaning</font></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#d9e6fc; padding:15px 15px 15px 15px;\"> \n",
    "Before operating on the data, it could be useful to identify eventual outliers. Proceding in this way can possibly lead to a better solution later on. The procedure is the following:\n",
    "<ul>\n",
    "<li> for each class calculate the mean \n",
    "<li> calculate the average distance and the standard deviation of the distances for each class\n",
    "<li> eliminate the images which distance from the mean is not in the interval <i>[average_distance - standard_dev,average_distance + standard_dev]</i>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "avg_dist_for_class = []\n",
    "std_for_class = []\n",
    "imgs_mean = []\n",
    "\n",
    "# for each class calculate the mean amd\n",
    "# calculate the average distance and the standard deviation of the distances \n",
    "for c in classes:\n",
    "    cls_img = mnist_training_images[mnist_training_labels==c]\n",
    "    img_mean = np.mean(cls_img,axis=0)\n",
    "    distances = [np.linalg.norm(img_mean-e) for e in cls_img]\n",
    "    std_for_class.append(np.std(distances))\n",
    "    avg_dist_for_class.append(np.mean(distances))\n",
    "    imgs_mean.append(img_mean)\n",
    "\n",
    "# eliminate the images which distance from the mean is not\n",
    "# in the interval [average_distance - standard_dev,average_distance + standard_dev]\n",
    "mask = []\n",
    "for e,lbl in zip(mnist_training_images,mnist_training_labels):\n",
    "    dist = np.linalg.norm(imgs_mean[lbl]-e)\n",
    "    if dist > avg_dist_for_class[lbl] + std_for_class[lbl] or \\\n",
    "            dist < avg_dist_for_class[lbl] - std_for_class[lbl]:\n",
    "        mask.append(False)\n",
    "    else:\n",
    "        mask.append(True)\n",
    "mask = np.array(mask)    \n",
    "filter_mnist_training_images=mnist_training_images[mask]\n",
    "filter_mnist_training_labels=mnist_training_labels[mask]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(range(0,10),[len(filter_mnist_training_images[filter_mnist_training_labels==c]) for c in range(0,10)])\n",
    "plt.title('MNIST Dataset filtered')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of elements')\n",
    "plt.show()\n",
    "\n",
    "print('Number of elements after filtering --->',len(filter_mnist_training_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#d9e6fc; padding:15px 15px 15px 15px;\"> \n",
    "From the graph above it is possible to notice that the classes are still not balanced. We are now balancing these classes, setting a number of images for each of them equal to 3500.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_dim = 3500\n",
    "num_classes = 10\n",
    "img_dim = 784\n",
    "new_mnist_training_images = np.array(functools.reduce(lambda x,y: np.append(x,y),\n",
    "                              [filter_mnist_training_images[filter_mnist_training_labels==c][:batch_dim] \n",
    "                               for c in range(0,10)])).reshape(batch_dim*num_classes,img_dim)\n",
    "new_mnist_training_labels = []\n",
    "for c in classes:\n",
    "    new_mnist_training_labels+=[c]*batch_dim\n",
    "len(new_mnist_training_labels)\n",
    "new_mnist_training_labels = np.array(new_mnist_training_labels)\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(range(0,10),[len(new_mnist_training_images[new_mnist_training_labels==c]) for c in range(0,10)])\n",
    "plt.title('MNIST Dataset filtered and balanced')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Number of elements')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#327191; vertical-align: middle; padding:5px 0px 10px 10px;\">\n",
    "    <h1><font color='white'>Naïve Bayes</font></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#d9e6fc; padding:15px 15px 15px 15px;\"> \n",
    "<h3>Pros and Cons</h3>\n",
    "<br>\n",
    "It is possible to identify pros and cons of using this kind of classifier (Naive Bayes). A NB classifier is a simple classifier, and it is also very fast to converge if the assumption of independence holds. If it doesn't hold this method still allows to arrive to a good solution, but not the best one. On the other hand, if data are skewed, that means more training examples for one class than another, it can cause the decision boundaries to be biased. This cause the classifier to unwillingly prefer one class over the other. A similar trend can be seen when the indipendence costraint is not respected: the likelihood tend to be greater for classes that most violate the indipendence assumption.\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#d9e6fc; padding:15px 15px 15px 15px;\"> \n",
    "<h3>Our Classifier</h3>\n",
    "<br>\n",
    "\n",
    "Our classifier consist in a python class able to calculate the mean and variance of the training data, in order to calculate the likelihood of the new data needed to be evaluated. In particular we used the probability density function in order to calculate the \"probability\", and not the actual probability calculated as the integral of the function. This because with the actual probability, the highest the value with respect to the mean, the highest is going to be the probability. In our case we want the values closest to the mean to have more impact, that's why the use of the pdf.<br><br>\n",
    "\n",
    "When the likelihood is computed, since we are implementing a naive method, we can consider the different probabilities of the different features as indipendent, and simply multiply them with one another. A common problem is to end up with a very small number at the end, since we are multiplying numbers that are less than 1.<br>\n",
    "A solution could be to use the logarithm, and since the logarithm of a multiplication is the sum of the log of each element, that is what is computed instead of the multiplication. One fact to keep in mind is the following: the log of a probability is less than 0, since the probability is less than 1. When we calculate the likelihood we obtain something less than 0 that is going to be divided by something that is also less than zero (<i>sum over all the classes of likelihood*prior</i>). The numerator is going to be smaller and smaller as the likelihood is moving from a value of 1 to 0: so we obtain something less than 0 and very small. When this result is divided by something also less than 0 is going to be a big positive number. <br>\n",
    "\n",
    "<h4>What we obtain?</h4> <br>\n",
    "The smaller the likelihood, the smaller the log of it, but at the end is going to be very big. At the end we are not looking for the max value, we are rather looking for the smallest one thanks to this inversion of sign.\n",
    "\n",
    "<h4>Log-Likelihood tuning</h4>\n",
    "<br>\n",
    "Sometimes it is possible that the log of the likelihood is -inf: this is due to a too small value of the likelihood. A part of data cleaning could be getting rid of -inf values, that during the sum of the logs will wrongly influenciate the result.\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Evaluate:\n",
    "    def __init__(self,classes,training_data,training_labels,test_data,test_labels):\n",
    "        self.classes = classes\n",
    "        self.training_data = training_data\n",
    "        self.training_labels = training_labels\n",
    "        self.test_data = test_data\n",
    "        self.test_labels = test_labels\n",
    "        self.mu = []\n",
    "        self.sigma2 = []\n",
    "        self.priors = np.array([])\n",
    "        self.predictions = np.array([])\n",
    "    \n",
    "    def mean_and_var(self):\n",
    "        for c in self.classes:\n",
    "            imgs = self.training_data[self.training_labels == c]\n",
    "            var = np.std(imgs,axis=0, ddof=1)\n",
    "            mn = np.mean(imgs,axis=0)\n",
    "            self.mu.append(mn)\n",
    "            self.sigma2.append(var)\n",
    "        self.mu = np.array(self.mu)\n",
    "        self.sigma2 = np.array(self.sigma2)\n",
    "\n",
    "        \n",
    "    def gaussian(self, x, m, v):\n",
    "        return 1 / np.sqrt(2 * np.pi * v) * np.exp(-(x - m)**2 / (2 * v))\n",
    "    \n",
    "    def likelihood(self, cls, data):\n",
    "        log_prob = np.array([np.log(self.gaussian(d, m, v)) if v > 0.0 else 0 for \n",
    "                         m, v, d in zip(self.mu[cls], self.sigma2[cls], data)])\n",
    "        mn = min(log_prob[log_prob!=-math.inf])\n",
    "        return sum(                \n",
    "                  [d if d != -math.inf else mn-1 for d in log_prob]  \n",
    "               )\n",
    "    \n",
    "    def prior(self):\n",
    "        pr = []\n",
    "        for c in self.classes:\n",
    "            mask = self.training_labels == c\n",
    "            pr.append(len(self.training_data[mask]))\n",
    "        self.priors =  np.array([e/sum(pr) for e in pr])\n",
    "        \n",
    "    \n",
    "    def predict(self):\n",
    "        labels = []\n",
    "        for d_test_img, d_test_lbl in zip(self.test_data,self.test_labels):            \n",
    "            probs = []\n",
    "            for c in self.classes:           \n",
    "                probs.append(self.likelihood(c,d_test_img)*self.priors[c])                \n",
    "            s = np.sum(probs)\n",
    "            probs = [p/s for p in probs]\n",
    "            labels.append(probs.index(min(probs)))\n",
    "        self.predictions = np.array(labels)        \n",
    "                \n",
    "    \n",
    "    def accuracy(self):\n",
    "        err = ok = 0\n",
    "        for pred, eff in zip(self.predictions, self.test_labels):\n",
    "            if pred == eff:\n",
    "                ok = ok + 1\n",
    "            else:\n",
    "                err = err + 1\n",
    "        return (ok,err)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#5a8da7; vertical-align: middle; padding:5px 0px 10px 10px;\">\n",
    "    <h3><font color='white'>Evaluation of Naive Bayes with MNIST training and test set</font></h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nomet/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:29: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "classes = [0,1,2,3,4,5,6,7,8,9]\n",
    "ev = Evaluate(classes,mnist_training_images,mnist_training_labels,mnist_testing_images,mnist_testing_labels)\n",
    "ev.prior()\n",
    "ev.mean_and_var()\n",
    "ev.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy --> 0.8159 with 8159 good classifications and 1841 wrong classifications\n"
     ]
    }
   ],
   "source": [
    "# ev.predict()\n",
    "accuracy = ev.accuracy()[0]/(ev.accuracy()[0]+ev.accuracy()[1])\n",
    "print(\"accuracy -->\",accuracy,\"with\",ev.accuracy()[0],\"good classifications and\",ev.accuracy()[1],\"wrong classifications\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save for eventual future use\n",
    "f = open('prediction_mnist','wb')\n",
    "pickle.dump(ev.predictions,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#5a8da7; vertical-align: middle; padding:5px 0px 10px 10px;\">\n",
    "    <h3><font color='white'>Evaluation of Naive Bayes with CFAR training and test set</font></h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = [0,1,2,3,4,5,6,7,8,9]\n",
    "ev_cfar10 = Evaluate(classes,cfar10_training_images,cfar10_training_labels,cfar10_test_images,cfar10_test_labels)\n",
    "ev_cfar10.prior()\n",
    "ev_cfar10.mean_and_var()\n",
    "ev_cfar10.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy --> 0.2722 with 2722 good classifications and 7278 wrong classifications\n"
     ]
    }
   ],
   "source": [
    "accuracy = ev_cfar10.accuracy()[0]/(ev_cfar10.accuracy()[0]+ev_cfar10.accuracy()[1])\n",
    "print(\"accuracy -->\",accuracy,\"with\",ev_cfar10.accuracy()[0],\n",
    "      \"good classifications and\",ev_cfar10.accuracy()[1],\"wrong classifications\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('prediction_mnist','wb')\n",
    "pickle.dump(ev_cfar10.predictions,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#5a8da7; vertical-align: middle; padding:5px 0px 10px 10px;\">\n",
    "    <h3><font color='white'>Performance discussion</font></h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#d9e6fc; padding:15px 15px 15px 15px;\"> \n",
    "We can see how the Naive Bayes classifier used on to make predictions on the mnist dataset performs quite good, with an accuracy of 81.59 percent, while on the cfar dataset the performances are not that good, only 27.22 percent. The reason could be that in the cfar dataset are present images more complicated and with number of colors greater than mnist images. This increase in features could have lead to a more difficult understanding of the image and to a higher misclassification rate.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#5a8da7; vertical-align: middle; padding:5px 0px 10px 10px;\">\n",
    "    <h3><font color='white'>Confusion Matrix</font></h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = pickle.load(open('prediction_mnist','rb'))\n",
    "matrix = []\n",
    "for c in classes:\n",
    "    mask = mnist_testing_labels == c\n",
    "    class_pred = predictions[mask]\n",
    "    matrix.append([len(class_pred[class_pred == c]) for c in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Classes    0    1    2    3    4    5    6    7    8    9\n",
      "---------  ---  ---  ---  ---  ---  ---  ---  ---  ---  ---\n",
      "        0  885    0    2    0    0   75    9    1    8    0\n",
      "        1    0  938   20    1    1   84    6    0   85    0\n",
      "        2   18    1  881    8    8   27   24    7   57    1\n",
      "        3    8    0   49  695    2  181    5    2   57   11\n",
      "        4    3    0    9    0  796   49   19    0   30   76\n",
      "        5    9    0    6   17    8  820   11    0   15    6\n",
      "        6   24    2   16    0   13   75  824    0    4    0\n",
      "        7   10    8   35    0   23   42    0  764   59   87\n",
      "        8    7    0   17   13    6  142    7    3  760   19\n",
      "        9   14    1    4    1   91   57    1    4   40  796\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(tabulate(np.c_[range(10),matrix], headers=['Classes']+classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background-color:#327191; vertical-align: middle; padding:5px 0px 10px 10px;\">\n",
    "    <h1><font color='white'>Bayesian Linear Regression</font></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#d9e6fc; padding:15px 15px 15px 15px;\"> \n",
    "The class below is used to create the bayesian linear regression method that will allow us to predict the type of an image using linear regression. Before being able to operate on the data, it is necessary to modify their structure, without changin the meaning and the content of each image. We defined the prior over w (<i>p(w)</i>) as a diagonal matrix with the element's value equal to 10000. \n",
    "<br>\n",
    "<h3>Problems encountered and solution proposed</h3>\n",
    "<br>\n",
    "We are working with discrete variables, but linear regression works with continues variables. In order to solve this problem we decided to treat each label as a one-hot vector. In this way we will not obtain a vector of weights of dimension <i>K+1</i> (where K is the grade of the polynomial and the + 1 is the grade zero term), but a matrix of dimension <i>K+1 x number_different_classes</i>. At the end of the prediction phase, for each test image not a single class will be returned but a set of N predictinos, where N is the number of different classes. Picking the highest value will give us the (hopefully) correct prediction.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BLR():\n",
    "    def __init__(self, classes, training_data, training_labels, test_data,test_labels, sigma, binary=True):     \n",
    "        # rapresent each class as a one-hot vector\n",
    "        self.classes = np.eye(len(classes)) if binary == True else classes\n",
    "        self.training_data = training_data\n",
    "        # rapresent each label as a one-hot vector\n",
    "        self.training_labels = [self.classes[c] for c in training_labels]\\\n",
    "                        if binary == True else training_labels\n",
    "        self.test_data = test_data\n",
    "        self.test_labels = test_labels\n",
    "        self.sigma = sigma   \n",
    "        self.binary = binary\n",
    "        \n",
    "    def adjust_data(self, k):\n",
    "        \"\"\"modify the input data to have them in the right format\"\"\"\n",
    "        \n",
    "        self.k = k\n",
    "        def redifine_data(x):\n",
    "            return np.array([\n",
    "                    np.array([x_i**n for n in range(k + 1)]).flatten() for x_i in np.array(x)\n",
    "                ])\n",
    "        self.training_data = redifine_data(self.training_data)\n",
    "        self.test_data = redifine_data(self.test_data)\n",
    "    \n",
    "    def generate_w(self):     \n",
    "        X = self.training_data\n",
    "        t0 = time.time()\n",
    "        X2 = X.T.dot(X)/self.sigma\n",
    "        S = np.eye(len(X2))*10000\n",
    "        X2inv = np.linalg.inv(X2+np.linalg.inv(S))\n",
    "        self.w = X2inv.dot(X.T).dot(self.training_labels)/self.sigma\n",
    "        \n",
    "    def make_prediction(self):\n",
    "        self.predictions = self.test_data.dot(self.w)\n",
    "        if self.binary == True:\n",
    "            self.predictions = [np.argmax(e) for e in self.predictions]\n",
    "    \n",
    "    def change_test_set(self, test_data, test_labels):\n",
    "        self.test_data = np.array([\n",
    "                    np.array([x_i**n for n in range(self.k + 1)]).flatten() for x_i in np.array(test_data)\n",
    "                ])\n",
    "        \n",
    "        self.test_labels = test_labels\n",
    "      \n",
    "    def accuracy(self):\n",
    "        err = ok = 0\n",
    "        for pred, eff in zip(self.predictions, self.test_labels):\n",
    "            if pred == eff:\n",
    "                ok = ok + 1\n",
    "            else:\n",
    "                err = err + 1\n",
    "        return (ok,err)\n",
    "    \n",
    "    def save_model(self, file_name):\n",
    "        f = open(file_name+'_w','wb')\n",
    "        pickle.dump(self.w,f)\n",
    "        f.close()\n",
    "        f = open(file_name+'_param','wb')\n",
    "        pickle.dump([self.sigma,self.binary,self.k,self.classes],f)\n",
    "        f.close()\n",
    "    \n",
    "    def load_model(self, file_name):\n",
    "        f = open(file_name+'_w','rb')\n",
    "        self.w = pickle.load(f)\n",
    "        f.close()\n",
    "        f = open(file_name+'_param','rb')\n",
    "        [self.sigma,self.binary,self.k,self.classes] = pickle.load(f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = [0,1,2,3,4,5,6,7,8,9]\n",
    "c = BLR(classes,mnist_training_images,mnist_training_labels,mnist_testing_images,mnist_testing_labels,0.05)\n",
    "t0 = time.time()\n",
    "c.adjust_data(2)\n",
    "c.generate_w()\n",
    "# c.save_model('model_k2_True_s05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8897, 1103)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.make_prediction()\n",
    "c.accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian linear regression cfar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = [0,1,2,3,4,5,6,7,8,9]\n",
    "c_cfar = BLR(classes,cfar10_training_images,cfar10_training_labels,cfar10_test_images,cfar10_test_labels,0.05)\n",
    "c_cfar.adjust_data(2)\n",
    "c_cfar.generate_w()\n",
    "# c.save_model('model_k2_True_s05')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8897, 1103)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_cfar.make_prediction()\n",
    "c_cfar.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classes = np.array([2,3,4])\n",
    "\n",
    "# train_data1 = np.array([[1990,14], [1990.2,14.4], [1989, 13.8]])\n",
    "# train_label1 = np.array([2,2,2])\n",
    "\n",
    "# train_data2 = np.array([[1991,15], [1991.3,14.5], [1990.7, 15.4]])\n",
    "# train_label2 = np.array([3,3,3])\n",
    "\n",
    "# train_data3 = np.array([[1992,15.94], [1992.1,16.56], [1991.95, 16]])\n",
    "# train_label3 = np.array([4,4,4])\n",
    "\n",
    "# test_data = np.array([[1991,15]])\n",
    "# test_label = np.array([3])\n",
    "\n",
    "# c1 = BLR(classes, train_data1, train_label1, test_data, test_label,0.05)\n",
    "# c2 = BLR(classes, train_data2, train_label2, test_data, test_label,0.05)\n",
    "# c3 = BLR(classes, train_data3, train_label3, test_data, test_label,0.05)\n",
    "\n",
    "# cls = [c1,c2,c3]\n",
    "\n",
    "# for c in cls:\n",
    "#     c.adjust_data(2)\n",
    "#     c.generate_w()\n",
    "# #     print(c.w)\n",
    "#     print(c.make_prediction())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#5a8da7; vertical-align: middle; padding:5px 0px 10px 10px;\">\n",
    "    <h3><font color='white'>Limitation of the previous approach</font></h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#d9e6fc; padding:15px 15px 15px 15px;\"> \n",
    "While using the one-hot vector to define a class for a given image, we are saying that the \"contribute\" of that image for a given class C is maximum, but completely inexistent for all the other classes. It could be better to procede in the following way:\n",
    "<ul>\n",
    "<li>given a class, take the images that are far away from the mean of the class \n",
    "<li>for that images look if the can contribute in defining also other classes (not a one-hot vector anymore)\n",
    "</ul>\n",
    "In order to exploit this idea we created a class, that behaves exactly as BLS, but with the addition of the methods to build up the labels to use in the training.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background-color:#327191; vertical-align: middle; padding:5px 0px 10px 10px;\">\n",
    "    <h1><font color='white'>Bayesian Linear Regression - new approach</font></h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#d9e6fc; padding:15px 15px 15px 15px;\"> \n",
    "We are starting to calculate the average image for each class and then calculating the distances of the image belonging to each class with the average image calculated before.<br>\n",
    "Having now the set of distances for each class, we evaluate mean and variance. Supposing that the distribution of the distances follows a normal distribution, mean and variance are used to evaluate the pdf value for each distance. If this value is small enough with respect to the maximum of the pdf, it means that the image is far away from the class mean, so it is possible to look how similar is to the other classes.<br>\n",
    "Operating in this way lead us to the following situation:\n",
    "<ul>\n",
    "<li>given a class, some images have as label a one-hot vector\n",
    "<li>given the same class, other images will have as label a vector with: a 1 with respect to their class and other numbers with respect to other classes.\n",
    "</ul>\n",
    "<br>\n",
    "In order to identify the images far enough from the mean, we are looking at the ratio between the pdf evaluated for a given image and the max of the pdf: if 1 - ratio is greater than 0.8, then the image is considered far from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdc5bcd8f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label of image is --> 2\n"
     ]
    }
   ],
   "source": [
    "len_set = len(mnist_training_images[mnist_training_labels==1])\n",
    "asd = np.mean(mnist_training_images[mnist_training_labels==1],axis=0)\n",
    "im = np.reshape(asd, (28,28))\n",
    "plt.imshow(im, cmap='gray')\n",
    "plt.show()\n",
    "print('label of image is --> '+str(mnist_testing_labels[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distances = [np.linalg.norm(asd-e) for e in mnist_training_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMwQkqWGGgCQ1zBCQpIb9P1EVZMPpUjmeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdc5bc7b6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.boxplot([np.linalg.norm(asd-e) for e in mnist_training_images])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07325"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def gaussian(x, m, v):\n",
    "    return 1 / np.sqrt(2 * np.pi * v) * np.exp(-(x - m)**2 / (2 * v))\n",
    "\n",
    "var = np.std(distances,axis=0, ddof=1)\n",
    "mn = np.mean(distances,axis=0)\n",
    "\n",
    "asd = np.array([1 - gaussian(e,mn,var)/0.018366605621986522 for e in distances])\n",
    "len(asd[asd<=0.8])/len(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class BLR_mod(BLR):\n",
    "    def __init__(self, classes, training_data,\n",
    "                 training_labels, test_data,test_labels, sigma, binary=True):\n",
    "        self.original_classes = classes\n",
    "        self.classes = np.eye(len(classes)) if binary == True else classes\n",
    "        self.training_data = training_data\n",
    "        self.training_labels = training_labels\n",
    "        self.test_data = test_data\n",
    "        self.test_labels = test_labels\n",
    "        self.mu = []\n",
    "        self.sigma2 = []\n",
    "        self.top_gaussian = []\n",
    "        self.class_mean = []\n",
    "        self.sigma = sigma   \n",
    "        self.binary = binary\n",
    "        \n",
    "    def gaussian(self, x, m, v):\n",
    "        return 1 / np.sqrt(2 * np.pi * v) * np.exp(-(x - m)**2 / (2 * v))\n",
    "    \n",
    "    def mean_and_var(self):\n",
    "        for c in self.original_classes:\n",
    "            class_mean = np.mean(self.training_data[self.training_labels == c],axis=0)\n",
    "            distances = [np.linalg.norm(class_mean-e) for e in self.training_data[self.training_labels == c]]\n",
    "            # var of the distances\n",
    "            var = np.std(distances,axis=0, ddof=1)\n",
    "            # mean of the distances\n",
    "            mn = np.mean(distances,axis=0)\n",
    "            self.class_mean.append(class_mean)\n",
    "            self.top_gaussian.append(self.gaussian(mn,mn,var))\n",
    "            self.mu.append(mn)\n",
    "            self.sigma2.append(var)\n",
    "        self.mu = np.array(self.mu)\n",
    "        self.sigma2 = np.array(self.sigma2)\n",
    "\n",
    "    \n",
    "    def labels(self):\n",
    "        labels = np.zeros((len(self.training_labels),10))\n",
    "        i = 0\n",
    "        for c,e in zip(self.training_labels,self.training_data):\n",
    "            dist = np.linalg.norm(self.class_mean[c]-e)\n",
    "            ratio = 1 - gaussian(dist,self.mu[c],self.sigma2[c])/self.top_gaussian[c]\n",
    "            labels[i] = self.classes[c]\n",
    "            if ratio > 0.8:\n",
    "                for cls in self.original_classes:\n",
    "                    if cls != c:\n",
    "                        dist = np.linalg.norm(self.class_mean[cls]-e)\n",
    "                        labels[i][cls] = gaussian(dist,self.mu[c],self.sigma2[c])/self.top_gaussian[cls]\n",
    "            i += 1\n",
    "        self.training_labels = labels\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "classes = [0,1,2,3,4,5,6,7,8,9]\n",
    "c = BLR_mod(classes,mnist_training_images,mnist_training_labels,mnist_testing_images,mnist_testing_labels,0.05)\n",
    "c.mean_and_var()\n",
    "c.labels()\n",
    "c.adjust_data(2)\n",
    "c.generate_w()\n",
    "# c.save_model('model_k2_True_s05_mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8846, 1154)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.make_prediction()\n",
    "c.accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
